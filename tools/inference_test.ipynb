{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'augmentation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m     15\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m../\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minference\u001b[39;00m \u001b[39mimport\u001b[39;00m do_inference\n",
      "File \u001b[0;32m~/code/inference.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m EAST\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdetect\u001b[39;00m \u001b[39mimport\u001b[39;00m detect\n\u001b[1;32m     16\u001b[0m CHECKPOINT_EXTENSIONS \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m.pth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.ckpt\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_args\u001b[39m():\n",
      "File \u001b[0;32m~/code/detect.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39malbumentations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpytorch\u001b[39;00m \u001b[39mimport\u001b[39;00m ToTensorV2\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39malbumentations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maugmentations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mresize\u001b[39;00m \u001b[39mimport\u001b[39;00m LongestMaxSize\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdataset\u001b[39;00m \u001b[39mimport\u001b[39;00m get_rotate_mat\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_valid_poly\u001b[39m(res, score_shape, scale):\n\u001b[1;32m     12\u001b[0m     \u001b[39m'''check if the poly in image scope\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m    Input:\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m        res        : restored poly in original image\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m        True if valid\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m    '''\u001b[39;00m\n",
      "File \u001b[0;32m~/code/dataset.py:16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimageio\u001b[39;00m \u001b[39mimport\u001b[39;00m imread\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maugmentation\u001b[39;00m \u001b[39mimport\u001b[39;00m ComposedTransformation, CropMethod_1\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39meast_dataset\u001b[39;00m \u001b[39mimport\u001b[39;00m generate_score_geo_maps\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcal_distance\u001b[39m(x1, y1, x2, y2):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'augmentation'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import json\n",
    "from argparse import ArgumentParser\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "from torch import cuda\n",
    "from model import EAST\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from inference import do_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = ArgumentParser()\n",
    "\n",
    "    # Conventional args\n",
    "    parser.add_argument('--data_dir', default=os.environ.get('SM_CHANNEL_EVAL'))\n",
    "    parser.add_argument('--model_dir', default=os.environ.get('SM_CHANNEL_MODEL', 'trained_models'))\n",
    "    parser.add_argument('--output_dir', default=os.environ.get('SM_OUTPUT_DATA_DIR', 'predictions'))\n",
    "\n",
    "    parser.add_argument('--device', default='cuda' if cuda.is_available() else 'cpu')\n",
    "    parser.add_argument('--input_size', type=int, default=1024)\n",
    "    parser.add_argument('--batch_size', type=int, default=1)\n",
    "\n",
    "    args = parser.parse_args('')\n",
    "\n",
    "    if args.input_size % 32 != 0:\n",
    "        raise ValueError('`input_size` must be a multiple of 32')\n",
    "\n",
    "    return args\n",
    "args = parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = EAST(pretrained=False).to(args.device)\n",
    "# Get paths to checkpoint files\n",
    "ckpt_fpath = osp.join(args.model_dir, 'latest.pth')\n",
    "\n",
    "if not osp.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir)\n",
    "\n",
    "print('Inference in progress')\n",
    "\n",
    "ufo_result = dict(images=dict())\n",
    "for split in ['public', 'private']:\n",
    "    print('Split: {}'.format(split))\n",
    "    split_result = do_inference(model, ckpt_fpath, args.data_dir, args.input_size,\n",
    "                                args.batch_size, split=split)\n",
    "    ufo_result['images'].update(split_result['images'])\n",
    "\n",
    "output_fname = 'output.csv'\n",
    "with open(osp.join(args.output_dir, output_fname), 'w') as f:\n",
    "    json.dump(ufo_result, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
